{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e7fca8-a2f5-4e92-9b3f-52234dde15c4",
   "metadata": {},
   "source": [
    "# Data Acquisition via Web Scraping (Rotten Tomatoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66630c-a28a-4314-8bfb-268f914740c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e0add-0743-4dac-b1c7-57f4fe09908b",
   "metadata": {},
   "source": [
    "## Phase 1: Setup and Request Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7a064-7ea1-4ba3-81eb-98a43e71fefc",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ff0da-936f-454b-826c-4f2fac81bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required Python modules for scraping and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests             # For submitting HTTP requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup # The primary tool for parsing HTML\n",
    "\n",
    "print(\"Modules imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6829a-e53a-4c9f-8b67-851fcbda4bca",
   "metadata": {},
   "source": [
    "### Obtain a User-agent String\n",
    "We get a User-agent string, which is necessary to identify our client. Scrapers should always send this header, as many sites block requests without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f3fc6-e2af-4187-997f-9721f88353fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use httpbin.org to get a standard User-agent string\n",
    "r = requests.get('https://httpbin.org/user-agent')\n",
    "useragent = json.loads(r.text)['user-agent']\n",
    "\n",
    "print(f\"Obtained User-agent: {useragent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2708de3-2344-42e3-b92e-0184923855c3",
   "metadata": {},
   "source": [
    "### Define Request Headers\n",
    "We compile the User-agent and an identifying \"From\" email into the headers dictionary. It's polite scraping practice to include contact info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3e80a-efd4-4409-8366-8287e4ae0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the headers dictionary\n",
    "headers = {'User-agent': useragent,\n",
    "          'From': replace_with_your_uva_email} # Example 'atr8e@virginia.edu'\n",
    "\n",
    "print(\"Headers dictionary defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a611a9d4-375c-49b4-83b0-02ee21f484f4",
   "metadata": {},
   "source": [
    "### Define the URL and Submit the GET Request\n",
    "This is the Extraction (E) phase of the web scrape. We submit the GET request to the target page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e1381-017a-4ed0-bfd0-ed1a112bf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target URL (Movies in Theaters page on Rotten Tomatoes)\n",
    "url = 'https://www.rottentomatoes.com/browse/movies_in_theaters/sort:top_box_office?page=5'\n",
    "\n",
    "# Submit the request with the custom headers\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "# A <Response [200]> means the request was successful\n",
    "print(f\"Request submitted. Status: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0838c-906e-435d-95f8-1e663adca275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run r.text below this if you want to see the raw output!\n",
    "# Recomment and rerun to get rid of the raw output, it's way too much!\n",
    "#r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3c841-f7d2-4b39-acef-781697591187",
   "metadata": {},
   "source": [
    "### Commentary on the Request\n",
    "The response object 'r' now contains the entire HTML source code of the webpage.\n",
    "\n",
    "The next step in the scraping process is to parse this raw text so we can easily search for the movie data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2f472-ee55-4fdd-b071-7253bf040c4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5dd3a-7fd1-452e-b4fc-778973171899",
   "metadata": {},
   "source": [
    "## Phase 2: HTML Parsing and Isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445a62c-9f87-41d5-b037-61db0b9ee85f",
   "metadata": {},
   "source": [
    "### Parse the HTML with BeautifulSoup\n",
    "This is the start of the Transformation (T) phase. BeautifulSoup turns the raw HTML text into a navigable Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9d450-8bc6-490a-bf33-7b11073950b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the raw HTML text (r.text) using the built-in 'html.parser'\n",
    "mysoup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "print(\"HTML content successfully parsed into a BeautifulSoup object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61ead2-988f-41b6-b26f-a2f16b6018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mysoup below this if you want to see the parsed output!\n",
    "# Recomment and rerun to get rid of the parsed output, it's way too much!\n",
    "#mysoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfb503-4ca3-4ddb-ac63-895e49109f13",
   "metadata": {},
   "source": [
    "### Isolate All Movie Tiles\n",
    "We use BeautifulSoup's find_all() method to locate the custom HTML tag used by Rotten Tomatoes to wrap each movie listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e0ecc-8420-4ccd-adef-a82345ab9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all elements corresponding to a single movie tile\n",
    "# The tag 'tile-dynamic' appears to wrap all the necessary data for one movie.\n",
    "mylist = mysoup.find_all('tile-dynamic')\n",
    "\n",
    "print(f\"Isolated {len(mylist)} movie tiles found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586998b-5f14-49c5-ab42-3e49bf94d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mylist below this if you want to see the selected output!\n",
    "# Recomment and rerun to get rid of the selected output, it's way too much!\n",
    "#mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff8d22-c819-4414-be0e-24d2b3b1eff0",
   "metadata": {},
   "source": [
    "### Isolate a Single Movie for Inspection\n",
    "To determine how to extract the data, we must first inspect the structure of a single movie tile. We grab the first element ([0]) from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a669ea9-efb4-4c50-8101-65b4b13f35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the first movie tile element to the variable 'm' for inspection\n",
    "m = mylist[0]\n",
    "\n",
    "print(\"Isolated the first movie tile (m) for inspection.\")\n",
    "# Display the element 'm' (optional: uncomment 'm' to see the full code block)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274332e-fe38-4708-8908-213be73534d8",
   "metadata": {},
   "source": [
    "### Extract the Movie Title\n",
    "We search within the single tile (m) for the specific HTML element containing the title, using the tag (span) and its class name (p--small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee90b5e-e656-4c36-9ca1-5507552b920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search within 'm' for the title: it's inside a <span> with the class 'p--small'\n",
    "# We grab the first result [0] and its string content\n",
    "title_example = m.find_all('span', 'p--small')[0].string\n",
    "\n",
    "print(f\"Example Title Extracted: {title_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e563d-62f4-4bd6-b1e3-78dd3be1a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e478c2-8a37-4f18-a29b-26459fff95ef",
   "metadata": {},
   "source": [
    "### Cleaning the Data (Trimming the List)\n",
    "Inspection of the page often reveals that the first few tiles are sometimes placeholders or ads. We trim the first 10 tiles to start with the main movie listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff2167-7170-44b8-8de1-392026ce0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the first 10 elements which may be placeholder/ad content\n",
    "mylist = mylist[10:]\n",
    "\n",
    "print(f\"Trimmed movie list to {len(mylist)} tiles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0565f44-4045-4aff-9454-17c857af4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mylist below this if you want to see the selected output!\n",
    "# Recomment and rerun to get rid of the selected output, it's way too much!\n",
    "#mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939db88-11ca-4f30-bd90-61b289bce182",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3a8ff-dda9-4cc7-a66b-cb5c14cf7371",
   "metadata": {},
   "source": [
    "## Phase 3: Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b8c3d-7597-4038-96d2-498fadc6744c",
   "metadata": {},
   "source": [
    "### Extract All Movie Titles\n",
    "Now that we know the path to the title, we use a list comprehension to efficiently extract the title from every element in our cleaned mylist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884250-3da4-4835-99c5-f3b639b26254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to extract and clean the title from every movie tile\n",
    "# .text is more robust than .string, and .strip() removes leading/trailing whitespace\n",
    "titles = [m.find_all('span', 'p--small')[0].text.strip() for m in mylist]\n",
    "\n",
    "print(f\"Extracted {len(titles)} movie titles.\")\n",
    "print(\"Example Titles:\")\n",
    "print(titles[:5]) # Display the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f664c8-b9b8-4513-9898-1d813602db99",
   "metadata": {},
   "source": [
    "### Extract Score Attributes (Audience Example)\n",
    "Scores often require checking specific HTML attributes. We examine one tile to find the HTML attribute (sentiment) used to store the score category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea79572-3244-4ab3-93b8-158ce325e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate a specific tile for attribute checking\n",
    "example_tile = mylist[0]\n",
    "\n",
    "# The 'score-icon-critics' tag holds the sentiment in an attribute named 'sentiment'\n",
    "critic_sentiment_example = example_tile.find_all('score-icon-critics')[0]['sentiment']\n",
    "\n",
    "print(f\"Example Critic Sentiment (Attribute): {critic_sentiment_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d745a8-6a25-42f8-8851-cdf248d6b5dc",
   "metadata": {},
   "source": [
    "### Extract All Score Components\n",
    "We repeat the list comprehension process for all required score components (Certified status, Score value, and Sentiment) for both Critics and Audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fbcf4-1bbf-4f37-b273-2b8f55073b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audience Data Extraction\n",
    "audiencecertified = [m.find_all('score-icon-audience')[0]['certified'] for m in mylist]\n",
    "audiencescore = [m.find_all('rt-text')[1].text.strip() for m in mylist]\n",
    "audiencesentiment = [m.find_all('score-icon-audience')[0]['sentiment'] for m in mylist]\n",
    "\n",
    "# Critics Data Extraction\n",
    "criticscertified = [m.find_all('score-icon-critics')[0]['certified'] for m in mylist]\n",
    "criticsscore = [m.find_all('rt-text')[0].text.strip() for m in mylist]\n",
    "criticssentiment = [m.find_all('score-icon-critics')[0]['sentiment'] for m in mylist]\n",
    "\n",
    "print(\"All six data lists (Scores, Sentiment, Certified status) successfully extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffdbe-a9de-45b3-9363-d5bf6ed3052a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533fb92-e7f1-4613-9751-1f1135a1fa49",
   "metadata": {},
   "source": [
    "## Phase 4: Data Consolidation and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97941cf5-291c-4712-8f29-b0197ce4312e",
   "metadata": {},
   "source": [
    "### Create the Final DataFrame\n",
    "We combine all the parallel lists into a single Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca502d-736c-4867-9182-b4ace32a4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_data = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'audience_certified': audiencecertified,\n",
    "    'audience_score': audiencescore,\n",
    "    'audience_sentiment': audiencesentiment,\n",
    "    'critics_certified': criticscertified,\n",
    "    'critics_score': criticsscore,\n",
    "    'critics_sentiment': criticssentiment\n",
    "})\n",
    "\n",
    "print(f\"DataFrame created with {len(rt_data)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af90034-528d-4d1e-887a-fb24c0e6f5ee",
   "metadata": {},
   "source": [
    "### View the Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afbc0b-73be-45d0-bf4b-4507126a1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting DataFrame\n",
    "display(rt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12038910-b9aa-48fb-a7b6-4b583a8371f3",
   "metadata": {},
   "source": [
    "### Extract Movie `$\\text{URL}$`s\n",
    "For fun, we can extract the relative URL for each movie, which is nested under a different tag. This shows how quickly you could start to think about how you would develop a web crawler that could grab URLs and traverse a whole site!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046677b9-8fac-4d15-945b-e73aa7ba1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <a> tag which contains the link, identified by its 'data-qa' attribute\n",
    "mylist_links = mysoup.find_all('a', attrs = {'data-qa':\"discovery-media-list-item-caption\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa1339-76fb-4ff6-82cc-b3845ed896bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'href' attribute and prepend the base URL\n",
    "urls = ['https://www.rottentomatoes.com' + m['href'] for m in mylist_links]\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85945f9e-2a15-4154-a06c-7d19c38f6f14",
   "metadata": {},
   "source": [
    "### Export to CSV\n",
    "This is the final Load (L) phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b27b04-5812-4322-b840-afc4bdce2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output filename\n",
    "output_filename = 'rotten_tomatoes_movies_in_theaters.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file without the pandas index\n",
    "rt_data.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"--- Load Phase Complete ---\")\n",
    "print(f\"Clean, scraped movie data successfully exported to: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
