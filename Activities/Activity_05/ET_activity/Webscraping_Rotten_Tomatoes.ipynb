{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e7fca8-a2f5-4e92-9b3f-52234dde15c4",
   "metadata": {},
   "source": [
    "# Data Acquisition via Web Scraping (Rotten Tomatoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66630c-a28a-4314-8bfb-268f914740c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e0add-0743-4dac-b1c7-57f4fe09908b",
   "metadata": {},
   "source": [
    "## Phase 1: Setup and Request Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7a064-7ea1-4ba3-81eb-98a43e71fefc",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513ff0da-936f-454b-826c-4f2fac81bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported.\n"
     ]
    }
   ],
   "source": [
    "# Import all required Python modules for scraping and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests             # For submitting HTTP requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup # The primary tool for parsing HTML\n",
    "\n",
    "print(\"Modules imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6829a-e53a-4c9f-8b67-851fcbda4bca",
   "metadata": {},
   "source": [
    "### Obtain a User-agent String\n",
    "We get a User-agent string, which is necessary to identify our client. Scrapers should always send this header, as many sites block requests without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f3fc6-e2af-4187-997f-9721f88353fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained User-agent: python-requests/2.32.4\n"
     ]
    }
   ],
   "source": [
    "# Use httpbin.org to get a standard User-agent string\n",
    "r = requests.get('https://httpbin.org/user-agent')\n",
    "useragent = json.loads(r.text)['user-agent']\n",
    "\n",
    "print(f\"Obtained User-agent: {useragent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2708de3-2344-42e3-b92e-0184923855c3",
   "metadata": {},
   "source": [
    "### Define Request Headers\n",
    "We compile the User-agent and an identifying \"From\" email into the headers dictionary. It's polite scraping practice to include contact info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd3e80a-efd4-4409-8366-8287e4ae0e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers dictionary defined.\n"
     ]
    }
   ],
   "source": [
    "# Define the headers dictionary\n",
    "headers = {'User-agent': useragent,\n",
    "          'From': 'mme3ar@virginia.edu'} # Example 'atr8e@virginia.edu'\n",
    "\n",
    "print(\"Headers dictionary defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a611a9d4-375c-49b4-83b0-02ee21f484f4",
   "metadata": {},
   "source": [
    "### Define the URL and Submit the GET Request\n",
    "This is the Extraction (E) phase of the web scrape. We submit the GET request to the target page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069e1381-017a-4ed0-bfd0-ed1a112bf495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request submitted. Status: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Define the target URL (Movies in Theaters page on Rotten Tomatoes)\n",
    "url = 'https://www.rottentomatoes.com/browse/movies_in_theaters/sort:top_box_office?page=5'\n",
    "\n",
    "# Submit the request with the custom headers\n",
    "r = requests.get(url, headers=headers)\n",
    "\n",
    "# A <Response [200]> means the request was successful\n",
    "print(f\"Request submitted. Status: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0838c-906e-435d-95f8-1e663adca275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run r.text below this if you want to see the raw output!\n",
    "# Recomment and rerun to get rid of the raw output, it's way too much!\n",
    "#r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3c841-f7d2-4b39-acef-781697591187",
   "metadata": {},
   "source": [
    "### Commentary on the Request\n",
    "The response object 'r' now contains the entire HTML source code of the webpage.\n",
    "\n",
    "The next step in the scraping process is to parse this raw text so we can easily search for the movie data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2f472-ee55-4fdd-b071-7253bf040c4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5dd3a-7fd1-452e-b4fc-778973171899",
   "metadata": {},
   "source": [
    "## Phase 2: HTML Parsing and Isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445a62c-9f87-41d5-b037-61db0b9ee85f",
   "metadata": {},
   "source": [
    "### Parse the HTML with BeautifulSoup\n",
    "This is the start of the Transformation (T) phase. BeautifulSoup turns the raw HTML text into a navigable Python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f9d450-8bc6-490a-bf33-7b11073950b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content successfully parsed into a BeautifulSoup object.\n"
     ]
    }
   ],
   "source": [
    "# Parse the raw HTML text (r.text) using the built-in 'html.parser'\n",
    "mysoup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "print(\"HTML content successfully parsed into a BeautifulSoup object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61ead2-988f-41b6-b26f-a2f16b6018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mysoup below this if you want to see the parsed output!\n",
    "# Recomment and rerun to get rid of the parsed output, it's way too much!\n",
    "#mysoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfb503-4ca3-4ddb-ac63-895e49109f13",
   "metadata": {},
   "source": [
    "### Isolate All Movie Tiles\n",
    "We use BeautifulSoup's find_all() method to locate the custom HTML tag used by Rotten Tomatoes to wrap each movie listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4e0ecc-8420-4ccd-adef-a82345ab9bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated 127 movie tiles found on the page.\n"
     ]
    }
   ],
   "source": [
    "# Find all elements corresponding to a single movie tile\n",
    "# The tag 'tile-dynamic' appears to wrap all the necessary data for one movie.\n",
    "mylist = mysoup.find_all('tile-dynamic')\n",
    "\n",
    "print(f\"Isolated {len(mylist)} movie tiles found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c586998b-5f14-49c5-ab42-3e49bf94d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mylist below this if you want to see the selected output!\n",
    "# Recomment and rerun to get rid of the selected output, it's way too much!\n",
    "#mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff8d22-c819-4414-be0e-24d2b3b1eff0",
   "metadata": {},
   "source": [
    "### Isolate a Single Movie for Inspection\n",
    "To determine how to extract the data, we must first inspect the structure of a single movie tile. We grab the first element ([0]) from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a669ea9-efb4-4c50-8101-65b4b13f35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated the first movie tile (m) for inspection.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tile-dynamic data-qa=\"tile\">\n",
       "<rt-img alt=\"One Battle After Another poster image\" loading=\"lazy\" slot=\"image\" src=\"https://resizing.flixster.com/J4-IRAM-JCRt1httKD5HlGu4kF8=/206x305/v2/https://resizing.flixster.com/RsxXU0Hem_FDFjs0xcKd_kOwEfg=/fit-in/180x240/v2/https://resizing.flixster.com/yepsxuaCu3f7igZnTo2huAOVtCU=/ems.cHJkLWVtcy1hc3NldHMvbW92aWVzLzNhNmQzNDA0LWFhYjQtNDA5Mi04OTMyLTA2Y2U2OWI5ZjVmYS5qcGc=\"></rt-img>\n",
       "<div data-track=\"scores\" slot=\"caption\">\n",
       "<div class=\"score-wrap\">\n",
       "<score-icon-critics certified=\"\" sentiment=\"positive\" size=\"1\"></score-icon-critics>\n",
       "<rt-text class=\"critics-score\" context=\"label\" size=\"1\">96%</rt-text>\n",
       "</div>\n",
       "<span class=\"p--small\">One Battle After Another</span>\n",
       "<span class=\"sr-only\">Link to One Battle After Another</span>\n",
       "</div>\n",
       "</tile-dynamic>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the first movie tile element to the variable 'm' for inspection\n",
    "m = mylist[0]\n",
    "\n",
    "print(\"Isolated the first movie tile (m) for inspection.\")\n",
    "# Display the element 'm' (optional: uncomment 'm' to see the full code block)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274332e-fe38-4708-8908-213be73534d8",
   "metadata": {},
   "source": [
    "### Extract the Movie Title\n",
    "We search within the single tile (m) for the specific HTML element containing the title, using the tag (span) and its class name (p--small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee90b5e-e656-4c36-9ca1-5507552b920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Title Extracted: One Battle After Another\n"
     ]
    }
   ],
   "source": [
    "# Search within 'm' for the title: it's inside a <span> with the class 'p--small'\n",
    "# We grab the first result [0] and its string content\n",
    "title_example = m.find_all('span', 'p--small')[0].string\n",
    "\n",
    "print(f\"Example Title Extracted: {title_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e563d-62f4-4bd6-b1e3-78dd3be1a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e478c2-8a37-4f18-a29b-26459fff95ef",
   "metadata": {},
   "source": [
    "### Cleaning the Data (Trimming the List)\n",
    "Inspection of the page often reveals that the first few tiles are sometimes placeholders or ads. We trim the first 10 tiles to start with the main movie listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ff2167-7170-44b8-8de1-392026ce0cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed movie list to 117 tiles.\n"
     ]
    }
   ],
   "source": [
    "# Trim the first 10 elements which may be placeholder/ad content\n",
    "mylist = mylist[10:]\n",
    "\n",
    "print(f\"Trimmed movie list to {len(mylist)} tiles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0565f44-4045-4aff-9454-17c857af4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run mylist below this if you want to see the selected output!\n",
    "# Recomment and rerun to get rid of the selected output, it's way too much!\n",
    "# mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939db88-11ca-4f30-bd90-61b289bce182",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3a8ff-dda9-4cc7-a66b-cb5c14cf7371",
   "metadata": {},
   "source": [
    "## Phase 3: Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b8c3d-7597-4038-96d2-498fadc6744c",
   "metadata": {},
   "source": [
    "### Extract All Movie Titles\n",
    "Now that we know the path to the title, we use a list comprehension to efficiently extract the title from every element in our cleaned mylist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08884250-3da4-4835-99c5-f3b639b26254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 117 movie titles.\n",
      "Example Titles:\n",
      "['HIM', 'The Conjuring: Last Rites', 'Downton Abbey: The Grand Finale', 'The Long Walk', 'A Big Bold Beautiful Journey']\n"
     ]
    }
   ],
   "source": [
    "# List comprehension to extract and clean the title from every movie tile\n",
    "# .text is more robust than .string, and .strip() removes leading/trailing whitespace\n",
    "titles = [m.find_all('span', 'p--small')[0].text.strip() for m in mylist]\n",
    "\n",
    "print(f\"Extracted {len(titles)} movie titles.\")\n",
    "print(\"Example Titles:\")\n",
    "print(titles[:5]) # Display the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f664c8-b9b8-4513-9898-1d813602db99",
   "metadata": {},
   "source": [
    "### Extract Score Attributes (Audience Example)\n",
    "Scores often require checking specific HTML attributes. We examine one tile to find the HTML attribute (sentiment) used to store the score category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea79572-3244-4ab3-93b8-158ce325e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Critic Sentiment (Attribute): negative\n"
     ]
    }
   ],
   "source": [
    "# Isolate a specific tile for attribute checking\n",
    "example_tile = mylist[0]\n",
    "\n",
    "# The 'score-icon-critics' tag holds the sentiment in an attribute named 'sentiment'\n",
    "critic_sentiment_example = example_tile.find_all('score-icon-critics')[0]['sentiment']\n",
    "\n",
    "print(f\"Example Critic Sentiment (Attribute): {critic_sentiment_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d745a8-6a25-42f8-8851-cdf248d6b5dc",
   "metadata": {},
   "source": [
    "### Extract All Score Components\n",
    "We repeat the list comprehension process for all required score components (Certified status, Score value, and Sentiment) for both Critics and Audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "137fbcf4-1bbf-4f37-b273-2b8f55073b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All six data lists (Scores, Sentiment, Certified status) successfully extracted.\n"
     ]
    }
   ],
   "source": [
    "# Audience Data Extraction\n",
    "audiencecertified = [m.find_all('score-icon-audience')[0]['certified'] for m in mylist]\n",
    "audiencescore = [m.find_all('rt-text')[1].text.strip() for m in mylist]\n",
    "audiencesentiment = [m.find_all('score-icon-audience')[0]['sentiment'] for m in mylist]\n",
    "\n",
    "# Critics Data Extraction\n",
    "criticscertified = [m.find_all('score-icon-critics')[0]['certified'] for m in mylist]\n",
    "criticsscore = [m.find_all('rt-text')[0].text.strip() for m in mylist]\n",
    "criticssentiment = [m.find_all('score-icon-critics')[0]['sentiment'] for m in mylist]\n",
    "\n",
    "print(\"All six data lists (Scores, Sentiment, Certified status) successfully extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046ffdbe-a9de-45b3-9363-d5bf6ed3052a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533fb92-e7f1-4613-9751-1f1135a1fa49",
   "metadata": {},
   "source": [
    "## Phase 4: Data Consolidation and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97941cf5-291c-4712-8f29-b0197ce4312e",
   "metadata": {},
   "source": [
    "### Create the Final DataFrame\n",
    "We combine all the parallel lists into a single Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfca502d-736c-4867-9182-b4ace32a4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created with 117 rows.\n"
     ]
    }
   ],
   "source": [
    "rt_data = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'audience_certified': audiencecertified,\n",
    "    'audience_score': audiencescore,\n",
    "    'audience_sentiment': audiencesentiment,\n",
    "    'critics_certified': criticscertified,\n",
    "    'critics_score': criticsscore,\n",
    "    'critics_sentiment': criticssentiment\n",
    "})\n",
    "\n",
    "print(f\"DataFrame created with {len(rt_data)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af90034-528d-4d1e-887a-fb24c0e6f5ee",
   "metadata": {},
   "source": [
    "### View the Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48afbc0b-73be-45d0-bf4b-4507126a1b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>audience_certified</th>\n",
       "      <th>audience_score</th>\n",
       "      <th>audience_sentiment</th>\n",
       "      <th>critics_certified</th>\n",
       "      <th>critics_score</th>\n",
       "      <th>critics_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HIM</td>\n",
       "      <td>false</td>\n",
       "      <td>58%</td>\n",
       "      <td>negative</td>\n",
       "      <td>false</td>\n",
       "      <td>31%</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Conjuring: Last Rites</td>\n",
       "      <td>false</td>\n",
       "      <td>78%</td>\n",
       "      <td>positive</td>\n",
       "      <td>false</td>\n",
       "      <td>59%</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Downton Abbey: The Grand Finale</td>\n",
       "      <td>true</td>\n",
       "      <td>96%</td>\n",
       "      <td>positive</td>\n",
       "      <td>true</td>\n",
       "      <td>92%</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Long Walk</td>\n",
       "      <td>false</td>\n",
       "      <td>85%</td>\n",
       "      <td>positive</td>\n",
       "      <td>true</td>\n",
       "      <td>88%</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Big Bold Beautiful Journey</td>\n",
       "      <td>false</td>\n",
       "      <td>59%</td>\n",
       "      <td>negative</td>\n",
       "      <td>false</td>\n",
       "      <td>37%</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Trade Secret</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Viva Verdi!</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Norita</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Peas and Carrots</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>A Writer's Odyssey 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title audience_certified audience_score  \\\n",
       "0                                HIM              false            58%   \n",
       "1          The Conjuring: Last Rites              false            78%   \n",
       "2    Downton Abbey: The Grand Finale               true            96%   \n",
       "3                      The Long Walk              false            85%   \n",
       "4       A Big Bold Beautiful Journey              false            59%   \n",
       "..                               ...                ...            ...   \n",
       "112                     Trade Secret                                     \n",
       "113                      Viva Verdi!                                     \n",
       "114                           Norita                                     \n",
       "115                 Peas and Carrots                                     \n",
       "116             A Writer's Odyssey 2                                     \n",
       "\n",
       "    audience_sentiment critics_certified critics_score critics_sentiment  \n",
       "0             negative             false           31%          negative  \n",
       "1             positive             false           59%          negative  \n",
       "2             positive              true           92%          positive  \n",
       "3             positive              true           88%          positive  \n",
       "4             negative             false           37%          negative  \n",
       "..                 ...               ...           ...               ...  \n",
       "112                                false                                  \n",
       "113                                false                                  \n",
       "114                                false                                  \n",
       "115                                false                                  \n",
       "116                                false                                  \n",
       "\n",
       "[117 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the resulting DataFrame\n",
    "display(rt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12038910-b9aa-48fb-a7b6-4b583a8371f3",
   "metadata": {},
   "source": [
    "### Extract Movie `$\\text{URL}$`s\n",
    "For fun, we can extract the relative URL for each movie, which is nested under a different tag. This shows how quickly you could start to think about how you would develop a web crawler that could grab URLs and traverse a whole site!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046677b9-8fac-4d15-945b-e73aa7ba1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the <a> tag which contains the link, identified by its 'data-qa' attribute\n",
    "mylist_links = mysoup.find_all('a', attrs = {'data-qa':\"discovery-media-list-item-caption\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecaa1339-76fb-4ff6-82cc-b3845ed896bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.rottentomatoes.com/m/him_2025_2',\n",
       " 'https://www.rottentomatoes.com/m/the_conjuring_last_rites',\n",
       " 'https://www.rottentomatoes.com/m/downton_abbey_the_grand_finale',\n",
       " 'https://www.rottentomatoes.com/m/the_long_walk_2025',\n",
       " 'https://www.rottentomatoes.com/m/a_big_bold_beautiful_journey',\n",
       " 'https://www.rottentomatoes.com/m/toy_story',\n",
       " 'https://www.rottentomatoes.com/m/weapons',\n",
       " 'https://www.rottentomatoes.com/m/freakier_friday',\n",
       " 'https://www.rottentomatoes.com/m/the_bad_guys_2',\n",
       " 'https://www.rottentomatoes.com/m/hamilton_2020',\n",
       " 'https://www.rottentomatoes.com/m/apollo_13',\n",
       " 'https://www.rottentomatoes.com/m/the_fantastic_four_first_steps',\n",
       " 'https://www.rottentomatoes.com/m/caught_stealing',\n",
       " 'https://www.rottentomatoes.com/m/the_history_of_sound',\n",
       " 'https://www.rottentomatoes.com/m/the_roses',\n",
       " 'https://www.rottentomatoes.com/m/jurassic_world_rebirth',\n",
       " 'https://www.rottentomatoes.com/m/superman_2025',\n",
       " 'https://www.rottentomatoes.com/m/the_baltimorons',\n",
       " 'https://www.rottentomatoes.com/m/f1_the_movie',\n",
       " 'https://www.rottentomatoes.com/m/twinless',\n",
       " 'https://www.rottentomatoes.com/m/lilo_and_stitch_2025',\n",
       " 'https://www.rottentomatoes.com/m/splitsville_2025',\n",
       " 'https://www.rottentomatoes.com/m/riefenstahl',\n",
       " 'https://www.rottentomatoes.com/m/plainclothes',\n",
       " 'https://www.rottentomatoes.com/m/the_summer_book',\n",
       " 'https://www.rottentomatoes.com/m/a_little_prayer',\n",
       " 'https://www.rottentomatoes.com/m/lurker',\n",
       " 'https://www.rottentomatoes.com/m/its_never_over_jeff_buckley',\n",
       " 'https://www.rottentomatoes.com/m/night_of_the_juggler',\n",
       " 'https://www.rottentomatoes.com/m/naked_ambition_2023',\n",
       " 'https://www.rottentomatoes.com/m/monk_in_pieces',\n",
       " 'https://www.rottentomatoes.com/m/dogtooth',\n",
       " 'https://www.rottentomatoes.com/m/familiar_touch',\n",
       " 'https://www.rottentomatoes.com/m/folktales',\n",
       " 'https://www.rottentomatoes.com/m/killer_of_sheep',\n",
       " 'https://www.rottentomatoes.com/m/kill_the_jockey',\n",
       " 'https://www.rottentomatoes.com/m/a_savage_art_the_life_and_cartoons_of_pat_oliphant',\n",
       " 'https://www.rottentomatoes.com/m/in_the_fire_of_war',\n",
       " 'https://www.rottentomatoes.com/m/rabbit_trap',\n",
       " 'https://www.rottentomatoes.com/m/a_photographic_memory',\n",
       " 'https://www.rottentomatoes.com/m/1154478-pariah',\n",
       " 'https://www.rottentomatoes.com/m/suspended_time',\n",
       " 'https://www.rottentomatoes.com/m/marlee_matlin_not_alone_anymore',\n",
       " 'https://www.rottentomatoes.com/m/one_battle_after_another',\n",
       " 'https://www.rottentomatoes.com/m/the_strangers_chapter_2',\n",
       " 'https://www.rottentomatoes.com/m/the_smashing_machine_2025',\n",
       " 'https://www.rottentomatoes.com/m/dead_of_winter_2025',\n",
       " 'https://www.rottentomatoes.com/m/gabbys_dollhouse_the_movie',\n",
       " 'https://www.rottentomatoes.com/m/eleanor_the_great',\n",
       " 'https://www.rottentomatoes.com/m/anemone_2025',\n",
       " 'https://www.rottentomatoes.com/m/bone_lake',\n",
       " 'https://www.rottentomatoes.com/m/good_boy_2025',\n",
       " 'https://www.rottentomatoes.com/m/spiderman',\n",
       " 'https://www.rottentomatoes.com/m/all_the_devils_are_here_2025',\n",
       " 'https://www.rottentomatoes.com/m/homebound_2025',\n",
       " 'https://www.rottentomatoes.com/m/avatar_the_way_of_water',\n",
       " 'https://www.rottentomatoes.com/m/bau_artist_at_war',\n",
       " 'https://www.rottentomatoes.com/m/satisfied',\n",
       " 'https://www.rottentomatoes.com/m/taylor_swift_the_official_release_party_of_a_showgirl',\n",
       " 'https://www.rottentomatoes.com/m/coyotes_2025',\n",
       " 'https://www.rottentomatoes.com/m/breed_of_greed',\n",
       " 'https://www.rottentomatoes.com/m/scared_shitless',\n",
       " 'https://www.rottentomatoes.com/m/killing_faith',\n",
       " 'https://www.rottentomatoes.com/m/shell_2024',\n",
       " 'https://www.rottentomatoes.com/m/bffs_2025',\n",
       " 'https://www.rottentomatoes.com/m/perfect_blue_1999',\n",
       " 'https://www.rottentomatoes.com/m/orwell',\n",
       " 'https://www.rottentomatoes.com/m/strange_journey_the_story_of_rocky_horror',\n",
       " 'https://www.rottentomatoes.com/m/the_ugly_2024',\n",
       " 'https://www.rottentomatoes.com/m/scurry',\n",
       " 'https://www.rottentomatoes.com/m/roads_of_fire',\n",
       " 'https://www.rottentomatoes.com/m/one_big_happy_family',\n",
       " 'https://www.rottentomatoes.com/m/soul_of_a_nation',\n",
       " 'https://www.rottentomatoes.com/m/trains_2024',\n",
       " 'https://www.rottentomatoes.com/m/peas_and_carrots']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 'href' attribute and prepend the base URL\n",
    "urls = ['https://www.rottentomatoes.com' + m['href'] for m in mylist_links]\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85945f9e-2a15-4154-a06c-7d19c38f6f14",
   "metadata": {},
   "source": [
    "### Export to CSV\n",
    "This is the final Load (L) phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78b27b04-5812-4322-b840-afc4bdce2d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Load Phase Complete ---\n",
      "Clean, scraped movie data successfully exported to: rotten_tomatoes_movies_in_theaters.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output filename\n",
    "output_filename = 'rotten_tomatoes_movies_in_theaters.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file without the pandas index\n",
    "rt_data.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"--- Load Phase Complete ---\")\n",
    "print(f\"Clean, scraped movie data successfully exported to: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
